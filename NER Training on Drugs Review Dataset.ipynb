{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER on Drugs Review Dataset\n",
    "\n",
    " The objective of this note book to perform a named entity recognition on drugs dataset.\n",
    "  - To add entities like drug name and drug condition\n",
    "  - Extract drug name and drug condition entities from new reviews which would assess in classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SpaCy recognizes the following built-in entity types:\n",
    "\n",
    "**PERSON** - People, including fictional.\n",
    "\n",
    "**NORP** - Nationalities or religious or political groups.\n",
    "\n",
    "**FAC** - Buildings, airports, highways, bridges, etc.\n",
    "\n",
    "**ORG** - Companies, agencies, institutions, etc.\n",
    "\n",
    "**GPE** - Countries, cities, states.\n",
    "\n",
    "**LOC** - Non-GPE locations, mountain ranges, bodies of water.\n",
    "\n",
    "**PRODUCT** - Objects, vehicles, foods, etc. (Not services.)\n",
    "\n",
    "**EVENT** - Named hurricanes, battles, wars, sports events, etc.\n",
    "\n",
    "**WORK_OF_ART** - Titles of books, songs, etc.\n",
    "\n",
    "**LAW** - Named documents made into laws.\n",
    "\n",
    "**LANGUAGE** - Any named language.\n",
    "\n",
    "**DATE** - Absolute or relative dates or periods.\n",
    "\n",
    "**TIME** - Times smaller than a day.\n",
    "\n",
    "**PERCENT** - Percentage, including \"%\".\n",
    "\n",
    "**MONEY** - Monetary values, including unit.\n",
    "\n",
    "**QUANTITY** - Measurements, as of weight or distance.\n",
    "\n",
    "**ORDINAL** - \"first\", \"second\", etc.\n",
    "\n",
    "**CARDINAL** - Numerals that do not fall under another type.\n",
    "\n",
    "#### Along with these, we will train SpaCy NER to recognize drug names as new entity. We will train 10000 reviews with drug names as DRUG entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from wordcloud import WordCloud, STOPWORDS # conda install -c conda-forge wordcloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy#conda install -c conda-forge spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from nltk.tokenize import word_tokenize\n",
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('drugsComTrain_raw.tsv',sep='\\t',index_col=0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22ce3d8c4b06c417cc1feaa506ce2fe8cb90c466"
   },
   "source": [
    "#### Initial inspection using word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab8f8c7e0150f11d8269a222a40300e3f53c3a35"
   },
   "outputs": [],
   "source": [
    "comment_words = ' '\n",
    "stopwords = set(STOPWORDS) \n",
    "for review in df_train['review']: \n",
    "    # typecaste each val to string \n",
    "    review = str(review).lower() \n",
    "    \n",
    "    # split the value \n",
    "    tokens = review.split()\n",
    "    comment_words = comment_words + ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewWords=sum(reviewWords,[])\n",
    "len(reviewWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "002bf5b042d014d996431c21f123fff0c71ad2c8"
   },
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS) \n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(reviewWords) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0)  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "270c03bc74fef57277858a908e5fe54cc42aca2f"
   },
   "source": [
    "#### extract entities for a custom entity by training a model in SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "024cbf9361b0e7c81b8a96389b89d550b91d84fa"
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8020c3de747eea8526161c9419e64cf1d132bb1e"
   },
   "outputs": [],
   "source": [
    "drug_list = df_train['drugName'].value_counts().index.tolist()\n",
    "drug_list = [x.lower() for x in drug_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1923fc19d08bf6263020b67399531f8d3bbe4c94"
   },
   "source": [
    "#### Training SpaCy NER for DRUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b09e126c5a1c459f0d95a1b0e2333540821e7463"
   },
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    processed_token = []\n",
    "    for token in review.split():\n",
    "        token = ''.join(e.lower() for e in token if e.isalnum())\n",
    "        processed_token.append(token)\n",
    "    return ' '.join(processed_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03b801b9144d333dc46df2e33000876e1cbde31b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Step 1: Let's create the training data\n",
    "count = 0\n",
    "TRAIN_DATA = []\n",
    "for _, item in df_train.iterrows():\n",
    "    ent_dict = {}\n",
    "    if count < 1000:\n",
    "        review = process_review(item['review'])\n",
    "        #We will find a drug and its positions once and add to the visited items.\n",
    "        visited_items = []\n",
    "        entities = []\n",
    "        for token in review.split():\n",
    "            if token in drug_list:\n",
    "                for i in re.finditer(token, review):\n",
    "                    if token not in visited_items:\n",
    "                        entity = (i.span()[0], i.span()[1], 'DRUG')\n",
    "                        visited_items.append(token)\n",
    "                        entities.append(entity)\n",
    "        if len(entities) > 0:\n",
    "            ent_dict['entities'] = entities\n",
    "            train_item = (review, ent_dict)\n",
    "            TRAIN_DATA.append(train_item)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7205a405bb52cf86a6772b050db7ceb8406c86ca"
   },
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "def train():\n",
    "    nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")\n",
    "    \n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "        \n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.5,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "            )\n",
    "        print(\"Losses\", losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5af0ee762614b9ecde11cadac31ee509d04f9347",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Step 2: Let's train custom model with the training data\n",
    "nlp2 = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74608012b1d1219782b5ffad213be79939378039"
   },
   "outputs": [],
   "source": [
    "#Test the model\n",
    "for text, _ in TRAIN_DATA[:10]:\n",
    "    doc = nlp2(text)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "316d8183851978a2651a61e2db19481011ce8063"
   },
   "outputs": [],
   "source": [
    "test_reviews = df_train.iloc[-10:, :]['review']\n",
    "for review in test_reviews:\n",
    "    review = process_review(review)\n",
    "    print(review)\n",
    "    doc = nlp2(review)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('________________________')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
