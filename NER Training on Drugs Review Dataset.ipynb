{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER on Drugs Review Dataset\n",
    "\n",
    "    - The objective of this note book to perform a named entity recognition on drugs dataset.\n",
    "        - To add entities like drug name and drug condition\n",
    "        - Extract drug name and drug condition entities from new reviews which would assess in classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SpaCy recognizes the following built-in entity types:\n",
    "\n",
    "**PERSON** - People, including fictional.\n",
    "\n",
    "**NORP** - Nationalities or religious or political groups.\n",
    "\n",
    "**FAC** - Buildings, airports, highways, bridges, etc.\n",
    "\n",
    "**ORG** - Companies, agencies, institutions, etc.\n",
    "\n",
    "**GPE** - Countries, cities, states.\n",
    "\n",
    "**LOC** - Non-GPE locations, mountain ranges, bodies of water.\n",
    "\n",
    "**PRODUCT** - Objects, vehicles, foods, etc. (Not services.)\n",
    "\n",
    "**EVENT** - Named hurricanes, battles, wars, sports events, etc.\n",
    "\n",
    "**WORK_OF_ART** - Titles of books, songs, etc.\n",
    "\n",
    "**LAW** - Named documents made into laws.\n",
    "\n",
    "**LANGUAGE** - Any named language.\n",
    "\n",
    "**DATE** - Absolute or relative dates or periods.\n",
    "\n",
    "**TIME** - Times smaller than a day.\n",
    "\n",
    "**PERCENT** - Percentage, including \"%\".\n",
    "\n",
    "**MONEY** - Monetary values, including unit.\n",
    "\n",
    "**QUANTITY** - Measurements, as of weight or distance.\n",
    "\n",
    "**ORDINAL** - \"first\", \"second\", etc.\n",
    "\n",
    "**CARDINAL** - Numerals that do not fall under another type.\n",
    "\n",
    "#### Along with these, we will train SpaCy NER to recognize drug names as new entity. We will train 10000 reviews with drug names as DRUG entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from wordcloud import WordCloud, STOPWORDS # conda install -c conda-forge wordcloud\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy#conda install -c conda-forge spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from nltk.tokenize import word_tokenize\n",
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>May 20, 2012</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>November 27, 2016</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        drugName                     condition  \\\n",
       "206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "95260                 Guanfacine                          ADHD   \n",
       "92703                     Lybrel                 Birth Control   \n",
       "138000                Ortho Evra                 Birth Control   \n",
       "35696   Buprenorphine / naloxone             Opiate Dependence   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "206461  \"It has no side effect, I take it in combinati...     9.0   \n",
       "95260   \"My son is halfway through his fourth week of ...     8.0   \n",
       "92703   \"I used to take another oral contraceptive, wh...     5.0   \n",
       "138000  \"This is my first time using any form of birth...     8.0   \n",
       "35696   \"Suboxone has completely turned my life around...     9.0   \n",
       "\n",
       "                     date  usefulCount  \n",
       "206461       May 20, 2012           27  \n",
       "95260      April 27, 2010          192  \n",
       "92703   December 14, 2009           17  \n",
       "138000   November 3, 2015           10  \n",
       "35696   November 27, 2016           37  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('drugsComTrain_raw.tsv',sep='\\t',index_col=0)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "22ce3d8c4b06c417cc1feaa506ce2fe8cb90c466"
   },
   "source": [
    "#### Initial inspection using word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab8f8c7e0150f11d8269a222a40300e3f53c3a35"
   },
   "outputs": [],
   "source": [
    "comment_words = ' '\n",
    "stopwords = set(STOPWORDS) \n",
    "for review in df_train['review']: \n",
    "    # typecaste each val to string \n",
    "    review = str(review).lower() \n",
    "    \n",
    "    # split the value \n",
    "    tokens = review.split()\n",
    "    comment_words = comment_words + ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewWords=sum(reviewWords,[])\n",
    "len(reviewWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "002bf5b042d014d996431c21f123fff0c71ad2c8"
   },
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS) \n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(reviewWords) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0)  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "270c03bc74fef57277858a908e5fe54cc42aca2f"
   },
   "source": [
    "#### extract entities for a custom entity by training a model in SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "024cbf9361b0e7c81b8a96389b89d550b91d84fa"
   },
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8020c3de747eea8526161c9419e64cf1d132bb1e"
   },
   "outputs": [],
   "source": [
    "drug_list = df_train['drugName'].value_counts().index.tolist()\n",
    "drug_list = [x.lower() for x in drug_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae54f574814eb58a2b83b2f6dd82271dccb82d89",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First let's check some NERs in first 10 reviews and remove date, time, ordinal and cardinal.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "count = 0\n",
    "for review in df_train['review']:\n",
    "    if count < 11:\n",
    "        doc = nlp(review)\n",
    "        ents = [(e.text, e.label_) for e in doc.ents if e.label_ not in ('DATE', 'TIME', 'ORDINAL', 'CARDINAL')]\n",
    "        print(ents)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1923fc19d08bf6263020b67399531f8d3bbe4c94"
   },
   "source": [
    "If we see the above entity extraction by built-in entities, we do not get proper extraction. So let's train the NER with custom data for DRUG.\n",
    "\n",
    "## Training SpaCy NER for DRUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b09e126c5a1c459f0d95a1b0e2333540821e7463"
   },
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    processed_token = []\n",
    "    for token in review.split():\n",
    "        token = ''.join(e.lower() for e in token if e.isalnum())\n",
    "        processed_token.append(token)\n",
    "    return ' '.join(processed_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03b801b9144d333dc46df2e33000876e1cbde31b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Step 1: Let's create the training data\n",
    "count = 0\n",
    "TRAIN_DATA = []\n",
    "for _, item in df_train.iterrows():\n",
    "    ent_dict = {}\n",
    "    if count < 1000:\n",
    "        review = process_review(item['review'])\n",
    "        #We will find a drug and its positions once and add to the visited items.\n",
    "        visited_items = []\n",
    "        entities = []\n",
    "        for token in review.split():\n",
    "            if token in drug_list:\n",
    "                for i in re.finditer(token, review):\n",
    "                    if token not in visited_items:\n",
    "                        entity = (i.span()[0], i.span()[1], 'DRUG')\n",
    "                        visited_items.append(token)\n",
    "                        entities.append(entity)\n",
    "        if len(entities) > 0:\n",
    "            ent_dict['entities'] = entities\n",
    "            train_item = (review, ent_dict)\n",
    "            TRAIN_DATA.append(train_item)\n",
    "            count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7205a405bb52cf86a6772b050db7ceb8406c86ca"
   },
   "outputs": [],
   "source": [
    "n_iter = 10\n",
    "def train():\n",
    "    nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")\n",
    "    \n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "        \n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "            \n",
    "    nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.5,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "            )\n",
    "        print(\"Losses\", losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5af0ee762614b9ecde11cadac31ee509d04f9347",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Step 2: Let's train custom model with the training data\n",
    "nlp2 = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74608012b1d1219782b5ffad213be79939378039"
   },
   "outputs": [],
   "source": [
    "#Test the model\n",
    "for text, _ in TRAIN_DATA[:10]:\n",
    "    doc = nlp2(text)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "316d8183851978a2651a61e2db19481011ce8063"
   },
   "outputs": [],
   "source": [
    "test_reviews = df_train.iloc[-10:, :]['review']\n",
    "for review in test_reviews:\n",
    "    review = process_review(review)\n",
    "    print(review)\n",
    "    doc = nlp2(review)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('________________________')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
